version: "1.0"
metadata:
  name: concurrent-steps
  description: Test workflow for concurrent step execution and dependency management
  author: lacquer-team

inputs:
  dataset_size:
    type: integer
    description: Size of dataset to process
    default: 1000
  
  processing_mode:
    type: string
    description: Mode of processing
    default: "parallel"
    
agents:
  data_agent:
    provider: anthropic
    model: claude-3-5-sonnet-20241022
    temperature: 0
    system_prompt: You are a data processing assistant that provides structured analysis.

workflow:

  state:
    parallel_results: {}
    processing_start: ${{ now() }}

  steps:
    # Independent steps that can run concurrently
    - id: generate_dataset_a
      run: "go run scripts/generate_dataset_a.go"
      with:
        size: ${{ inputs.dataset_size }}
      outputs:
        dataset_name:
          type: string
          description: Name of the dataset
        size:
          type: integer
          description: Dataset size
        data_type:
          type: string
          description: Type of data
        generation_time:
          type: integer
          description: Time taken to generate
        samples:
          type: array
          description: Sample data points
        metadata:
          type: object
          description: Dataset metadata

    - id: generate_dataset_b
      run: "go run scripts/generate_dataset_b.go"
      with:
        size: ${{ inputs.dataset_size }}
      outputs:
        dataset_name:
          type: string
          description: Name of the dataset
        size:
          type: integer
          description: Dataset size
        data_type:
          type: string
          description: Type of data
        generation_time:
          type: integer
          description: Time taken to generate
        categories:
          type: array
          description: Data categories
        metadata:
          type: object
          description: Dataset metadata

    - id: generate_dataset_c
      run: "go run scripts/generate_dataset_c.go"
      with:
        size: ${{ inputs.dataset_size }}
      outputs:
        dataset_name:
          type: string
          description: Name of the dataset
        size:
          type: integer
          description: Dataset size
        data_type:
          type: string
          description: Type of data
        generation_time:
          type: integer
          description: Time taken to generate
        sample_texts:
          type: array
          description: Sample text data
        metadata:
          type: object
          description: Dataset metadata

    # Step that depends on dataset_a
    - id: analyze_numerical_data
      agent: data_agent
      prompt: |
        Analyze this numerical dataset:
        - Dataset: ${{ steps.generate_dataset_a.outputs.dataset_name }}
        - Size: ${{ steps.generate_dataset_a.outputs.size }}
        - Samples: ${{ steps.generate_dataset_a.outputs.samples }}
        
        Provide statistical analysis in JSON format:
        {
          "mean": number,
          "median": number,
          "analysis": "description of the data"
        }
      outputs:
        mean:
          type: integer
          description: Mean of the data
        median:
          type: integer
          description: Median of the data
        analysis:
          type: string
          description: Analysis description

    # Step that depends on dataset_b  
    - id: analyze_categorical_data
      run: "go run scripts/analyze_categorical_data.go"
      with:
        categories: ${{ join(steps.generate_dataset_b.outputs.categories, ',') }}
        dataset_name: ${{ steps.generate_dataset_b.outputs.dataset_name }}
      outputs:
        category_count:
          type: integer
          description: Number of categories
        most_common:
          type: string
          description: Most common category
        diversity_score:
          type: integer
          description: Diversity score
        analysis:
          type: string
          description: Categorical analysis

    # Step that depends on dataset_c
    - id: analyze_textual_data
      run: "go run scripts/analyze_textual_data.go"
      with:
        texts: ${{ join(steps.generate_dataset_c.outputs.sample_texts, ',') }}
        dataset_name: ${{ steps.generate_dataset_c.outputs.dataset_name }}
      outputs:
        text_count:
          type: integer
          description: Number of text samples
        average_length:
          type: integer
          description: Average text length
        language:
          type: string
          description: Detected language
        analysis:
          type: string
          description: Text analysis

    # Step that depends on multiple analysis results (must wait for all analyses)
    - id: combine_analyses
      run: "go run scripts/combine_analyses.go"
      with:
        numerical_mean: ${{ steps.analyze_numerical_data.outputs.mean }}
        categorical_count: ${{ steps.analyze_categorical_data.outputs.category_count }}
        textual_count: ${{ steps.analyze_textual_data.outputs.text_count }}
      updates:
        parallel_results: ${{ steps.combine_analyses.outputs }}
        processing_end: ${{ now() }}
      outputs:
        numerical_insights:
          type: object
          description: Insights from numerical analysis
        categorical_insights:
          type: object
          description: Insights from categorical analysis
        textual_insights:
          type: object
          description: Insights from textual analysis
        combined_score:
          type: integer
          description: Combined analysis score
        overall_assessment:
          type: string
          description: Overall assessment

    # Final step that summarizes timing and concurrency benefits
    - id: concurrency_summary
      run: "go run scripts/concurrency_summary.go"
      with:
        gen_time_a: ${{ steps.generate_dataset_a.outputs.generation_time }}
        gen_time_b: ${{ steps.generate_dataset_b.outputs.generation_time }}
        gen_time_c: ${{ steps.generate_dataset_c.outputs.generation_time }}
      outputs:
        generation_times:
          type: object
          description: Individual generation times
        execution_analysis:
          type: object
          description: Analysis of concurrent vs sequential execution
        concurrency_benefits:
          type: array
          description: Benefits of concurrent execution

  outputs:
    # Dataset generation results (these ran concurrently)
    generated_datasets: {
      "dataset_a": "${{ steps.generate_dataset_a.outputs }}",
      "dataset_b": "${{ steps.generate_dataset_b.outputs }}",
      "dataset_c": "${{ steps.generate_dataset_c.outputs }}"
    }
    
    # Analysis results (these depended on dataset generation)
    analysis_results: {
      "numerical": "${{ steps.analyze_numerical_data.outputs }}",
      "categorical": "${{ steps.analyze_categorical_data.outputs }}",
      "textual": "${{ steps.analyze_textual_data.outputs }}"
    }
    
    # Combined analysis (depended on all individual analyses)
    combined_analysis: "${{ steps.combine_analyses.outputs }}"
    
    # Concurrency performance metrics
    concurrency_metrics: "${{ steps.concurrency_summary.outputs }}"
    
    # Processing summary
    processing_summary: "Processed ${{ inputs.dataset_size }} records across 3 datasets using concurrent execution with dependency management"